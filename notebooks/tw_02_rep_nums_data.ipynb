{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/2020_United_States_House_of_Representatives_elections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "html5lib not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/teresawhitesell/Desktop/ds_bootcamp/repos/webscraping-open-secrets-bone_scrapers/notebooks/tw_02_rep_nums_data.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/teresawhitesell/Desktop/ds_bootcamp/repos/webscraping-open-secrets-bone_scrapers/notebooks/tw_02_rep_nums_data.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39mread_html(\u001b[39mstr\u001b[39m(soup\u001b[39m.\u001b[39mfindAll(\u001b[39m'\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m'\u001b[39m, attrs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mwikitable\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msortable\u001b[39m\u001b[39m'\u001b[39m})[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mtbody\u001b[39m\u001b[39m'\u001b[39m)))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:1205\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links)\u001b[0m\n\u001b[1;32m   1201\u001b[0m validate_header_arg(header)\n\u001b[1;32m   1203\u001b[0m io \u001b[39m=\u001b[39m stringify_path(io)\n\u001b[0;32m-> 1205\u001b[0m \u001b[39mreturn\u001b[39;00m _parse(\n\u001b[1;32m   1206\u001b[0m     flavor\u001b[39m=\u001b[39mflavor,\n\u001b[1;32m   1207\u001b[0m     io\u001b[39m=\u001b[39mio,\n\u001b[1;32m   1208\u001b[0m     match\u001b[39m=\u001b[39mmatch,\n\u001b[1;32m   1209\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   1210\u001b[0m     index_col\u001b[39m=\u001b[39mindex_col,\n\u001b[1;32m   1211\u001b[0m     skiprows\u001b[39m=\u001b[39mskiprows,\n\u001b[1;32m   1212\u001b[0m     parse_dates\u001b[39m=\u001b[39mparse_dates,\n\u001b[1;32m   1213\u001b[0m     thousands\u001b[39m=\u001b[39mthousands,\n\u001b[1;32m   1214\u001b[0m     attrs\u001b[39m=\u001b[39mattrs,\n\u001b[1;32m   1215\u001b[0m     encoding\u001b[39m=\u001b[39mencoding,\n\u001b[1;32m   1216\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   1217\u001b[0m     converters\u001b[39m=\u001b[39mconverters,\n\u001b[1;32m   1218\u001b[0m     na_values\u001b[39m=\u001b[39mna_values,\n\u001b[1;32m   1219\u001b[0m     keep_default_na\u001b[39m=\u001b[39mkeep_default_na,\n\u001b[1;32m   1220\u001b[0m     displayed_only\u001b[39m=\u001b[39mdisplayed_only,\n\u001b[1;32m   1221\u001b[0m     extract_links\u001b[39m=\u001b[39mextract_links,\n\u001b[1;32m   1222\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:982\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m    980\u001b[0m retained \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[39mfor\u001b[39;00m flav \u001b[39min\u001b[39;00m flavor:\n\u001b[0;32m--> 982\u001b[0m     parser \u001b[39m=\u001b[39m _parser_dispatch(flav)\n\u001b[1;32m    983\u001b[0m     p \u001b[39m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/html.py:931\u001b[0m, in \u001b[0;36m_parser_dispatch\u001b[0;34m(flavor)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[39mif\u001b[39;00m flavor \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbs4\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhtml5lib\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    930\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _HAS_HTML5LIB:\n\u001b[0;32m--> 931\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mhtml5lib not found, please install it\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _HAS_BS4:\n\u001b[1;32m    933\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mBeautifulSoup4 (bs4) not found, please install it\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: html5lib not found, please install it"
     ]
    }
   ],
   "source": [
    "pd.read_html(str(soup.findAll('table', attrs = {'class': 'wikitable', 'class': 'sortable'})[0].find('tbody')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "28",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/teresawhitesell/Desktop/ds_bootcamp/repos/webscraping-open-secrets-bone_scrapers/notebooks/tw_02_rep_nums_data.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teresawhitesell/Desktop/ds_bootcamp/repos/webscraping-open-secrets-bone_scrapers/notebooks/tw_02_rep_nums_data.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m state_dist \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_html(\u001b[39mstr\u001b[39m(soup\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m'\u001b[39m, attrs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mwikitable\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39msortable\u001b[39m\u001b[39m'\u001b[39m})))[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdrop(\u001b[39m50\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/teresawhitesell/Desktop/ds_bootcamp/repos/webscraping-open-secrets-bone_scrapers/notebooks/tw_02_rep_nums_data.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m state_dist \u001b[39m=\u001b[39m state_dist[\u001b[39m'\u001b[39m\u001b[39mState\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTotal seats\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3806\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[39mif\u001b[39;00m is_single_key:\n\u001b[1;32m   3805\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 3806\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   3808\u001b[0m     \u001b[39mif\u001b[39;00m is_integer(indexer):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:3857\u001b[0m, in \u001b[0;36mDataFrame._getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3855\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getitem_multilevel\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   3856\u001b[0m     \u001b[39m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[0;32m-> 3857\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   3858\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, (\u001b[39mslice\u001b[39m, np\u001b[39m.\u001b[39mndarray)):\n\u001b[1;32m   3859\u001b[0m         new_columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns[loc]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2927\u001b[0m, in \u001b[0;36mMultiIndex.get_loc\u001b[0;34m(self, key, method)\u001b[0m\n\u001b[1;32m   2925\u001b[0m \u001b[39mif\u001b[39;00m keylen \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnlevels \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_unique:\n\u001b[1;32m   2926\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2927\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(key)\n\u001b[1;32m   2928\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   2929\u001b[0m         \u001b[39m# e.g. test_partial_slicing_with_multiindex partial string slicing\u001b[39;00m\n\u001b[1;32m   2930\u001b[0m         loc, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_loc_level(key, \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnlevels)))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:782\u001b[0m, in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:1920\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.UInt64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:1930\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.UInt64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 28"
     ]
    }
   ],
   "source": [
    "state_dist = pd.read_html(str(soup.find('table', attrs = {'class': 'wikitable', 'class': 'sortable'})))[0].drop(50)\n",
    "state_dist = state_dist['State', 'Total seats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code inside read_html results in a list with one element, flatten by calling [0], df results\n",
    "# drop index 50 (total row)\n",
    "\n",
    "\n",
    "state_rep_num = pd.read_html(str(soup.find('table')))[0].drop(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need list of state abbreviations\n",
    "\n",
    "abb_url = 'https://www.yourdictionary.com/articles/state-abbreviations'\n",
    "\n",
    "abb_res = requests.get(abb_url)\n",
    "\n",
    "abb_soup = BeautifulSoup(abb_res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_abb = pd.read_html(str(abb_soup.find('table')), header = 0)[0].drop('Traditional Abbreviation', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['state', 'representatives'], dtype='object')\n",
      "Index(['State Name', 'USPS Abbreviation'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(state_rep_num.columns)\n",
    "print(state_abb.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>representatives</th>\n",
       "      <th>state_abbr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>7</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  representatives state_abbr\n",
       "0  Alabama                7         AL"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join state_rep_num to state_abb\n",
    "\n",
    "st_rep = pd.merge(state_rep_num, state_abb, left_on = 'state', right_on = 'State Name', how = 'inner')\\\n",
    "    .drop('State Name', axis = 1).rename({'USPS Abbreviation': 'state_abbr'}, axis = 1)\n",
    "\n",
    "st_rep.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "435"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example url\n",
    "# https://www.opensecrets.org/races/candidates?cycle=2020&id=TN07&spec=N.\n",
    "\n",
    "url_base = 'https://www.opensecrets.org/races/candidates?cycle=2020&id='\n",
    "url_suffix = '&spec=N'\n",
    "\n",
    "url_list = []\n",
    "\n",
    "for r in range(len(st_rep)):\n",
    "    abbr = st_rep.loc[r]['state_abbr']\n",
    "    rep_num = st_rep.loc[r]['representatives']\n",
    "\n",
    "    for d in range(1, rep_num + 1):\n",
    "        url = f\"{url_base}{abbr}{str(d).zfill(2)}{url_suffix}\"\n",
    "        url_list.append(url)\n",
    "\n",
    "st_rep['urls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(url_list).to_csv('../data/dist_urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
