{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(val):\n",
    "    \"\"\"\n",
    "    Converts a string to a float by removing non-numeric and non-decimal characters.\n",
    "\n",
    "    Args:\n",
    "        val (str): The input string to be converted to a float.\n",
    "\n",
    "    Returns:\n",
    "        float: The converted float value.\n",
    "\n",
    "    Example:\n",
    "        convert_to_float(\"$123.45\")  # Returns 123.45\n",
    "    \"\"\"\n",
    "    val = re.sub(r\"[^0-9\\.]\", \"\", val)\n",
    "    return float(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_info(member_div):\n",
    "    \"\"\"\n",
    "    Extracts candidate information from a BeautifulSoup element (a div) representing a candidate.\n",
    "\n",
    "    Args:\n",
    "        member_div (BeautifulSoup): The BeautifulSoup element containing candidate information.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted candidate information, including Name, Affiliation, Incumbent status,\n",
    "        Winner status, Vote Percentage, Cash Raised, and Cash Spent.\n",
    "\n",
    "    Example:\n",
    "        get_candidate_info(member_div)  # Returns a dictionary with candidate information.\n",
    "    \"\"\"\n",
    "    results = {\"Name\": \"\", \"Affiliation\": \"\", \"Incumbent\": 0, \"Winner\": 0, \"Vote %\": \"\", \"Cash Raised\": \"\", \"Cash Spent\": \"\"}\n",
    "\n",
    "    # handle the case of the incumbent\n",
    "    if member_div.find(\"a\") != None:\n",
    "        candidate_text = member_div.find(\"a\").text\n",
    "        affiliation = re.findall(r\"\\([\\w+]\\)\", candidate_text)[0][1] if re.findall(r\"\\([\\w+]\\)\", candidate_text) else \"\"\n",
    "        incumbent = 1 if \"Incumbent\" in candidate_text else 0\n",
    "        results[\"Incumbent\"] = incumbent\n",
    "        candidate_text = re.sub(r\"\\([\\w+]\\)\", \"\", candidate_text)\n",
    "        candidate_text = re.sub(r\"Incumbent\", \"\", candidate_text)\n",
    "        name = re.sub(\"[^0-9a-zA-Z\\s]+\", \"\", candidate_text).strip()\n",
    "    # get information for non-incumbents\n",
    "    else:\n",
    "        txt = member_div.find(\"h2\").find(\"strong\").text.strip()\n",
    "        candidate_info = re.findall(r\"[^\\n\\t+]+\", txt)\n",
    "        affiliation = re.findall(r\"\\([\\w+]\\)\", candidate_info[0])[0][1] if re.findall(r\"\\([\\w+]\\)\", candidate_info[0])[0][1] else \"\"\n",
    "        name = re.sub(r\"\\([\\w+]\\)\", \"\", candidate_info[0]).strip()\n",
    "    \n",
    "    # collect the name and affiliation of the candidate collected from above\n",
    "    results[\"Name\"] = name\n",
    "    results[\"Affiliation\"] = affiliation\n",
    "    \n",
    "    # check if the candidate is a winner\n",
    "    if member_div.find(\"span\", attrs={'class': 'winner'}):\n",
    "        results[\"Winner\"] = 1\n",
    "    # get the vote percentage\n",
    "    if member_div.find(\"span\", attrs={'class': 'Members--vote-pct'}):\n",
    "        votepctstr = member_div.find(\"span\", attrs={'class': 'Members--vote-pct'}).text\n",
    "        votepct = re.findall(r\"\\d+\\.\\d+%\", votepctstr)[0]\n",
    "        results[\"Vote %\"] = convert_to_float(votepct)\n",
    "    cash_numbers = member_div.find(\"table\", attrs={'class': 'Members--table'}).findAll(\"td\", attrs={'class': 'Members--number'})\n",
    "    # get the cash amounts\n",
    "    if cash_numbers:\n",
    "        results[\"Cash Raised\"] = convert_to_float(cash_numbers[0].text)\n",
    "        results[\"Cash Spent\"] = convert_to_float(cash_numbers[1].text)\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_candidates_for_district_url(url):\n",
    "    \"\"\"\n",
    "    Retrieves and extracts information about all candidates for a specific district from a given URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the page containing candidate information for a specific district.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary represents candidate information for the district. \n",
    "              Returns an empty list if the URL is not found (404 error).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an exception if the response status code is not 200 (OK).\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        #get all the divs that contain the candidates\n",
    "        member_divs = soup.findAll(\"div\", attrs={'class': 'Members--list-item'})\n",
    "        #call get_candidate_info() to get the information on each of the divs and store them in a variable called candidate_list\n",
    "        candidate_list = [get_candidate_info(div) for div in member_divs]\n",
    "\n",
    "        # get the state and district number directly from the URL\n",
    "        state_districtnum = re.findall(r'[A-Z][A-Z]\\d+', url)[0]\n",
    "        state = state_districtnum[:2]\n",
    "        districtnum = re.findall(r'\\d+', state_districtnum)[0]\n",
    "\n",
    "        # add state and district number to each entry in candidate_list\n",
    "        for candidate in candidate_list:\n",
    "            candidate[\"State\"] = state\n",
    "            candidate[\"District Number\"] = districtnum\n",
    "        return candidate_list\n",
    "    # handle exceptions\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP Error: {e}\")\n",
    "        return []  # Return an empty list in case of a 404 error.\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e} for url {url}\")\n",
    "        return []  # Return an empty list for any other exceptions.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is just to test the get_all_candidates_for_district_url() here by giving it different urls for districts. \n",
    "Example urls:\n",
    "URL = \"https://www.opensecrets.org/races/candidates?cycle=2020&id=GA14&spec=N\"\n",
    "URL = \"https://www.opensecrets.org/races/candidates?cycle=2020&id=CO0314&spec=N\"\n",
    "\"\"\"\n",
    "\n",
    "URL = \"https://www.opensecrets.org/races/candidates?cycle=2020&id=GA14&spec=N\"\n",
    "candidate_list = get_all_candidates_for_district_url(URL)\n",
    "candidate_df = pd.DataFrame(candidate_list)\n",
    "candidate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_url(abbrev, reps):\n",
    "    \"\"\"\n",
    "    Creates a URL for retrieving candidate information for a specific state and distric.\n",
    "\n",
    "    Args:\n",
    "        abbrev (str): A string representing the state abbreviation (e.g., 'CA' for California).\n",
    "        reps (str): A string representing the district or representative identifier.\n",
    "\n",
    "    Returns:\n",
    "        str: A URL string for accessing candidate information for the specified state and district in the 2020 election cycle.\n",
    "\n",
    "    Example:\n",
    "        create_url(\"CA\", \"12\")  # Returns a URL for California's 12th district in the 2020 election cycle.\n",
    "    \"\"\"\n",
    "    return f\"https://www.opensecrets.org/races/candidates?cycle=2020&id={abbrev}{reps}&spec=N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import a file containing all the US State abbreviations and store as a df\n",
    "states_abbrev_df = pd.read_csv('..\\\\data\\\\states.csv')\n",
    "\n",
    "\n",
    "# Generate URLs for congressional districts for all states using the URL provided\n",
    "URL = \"https://www.britannica.com/topic/United-States-House-of-Representatives-Seats-by-State-1787120\"\n",
    "response = requests.get(URL)\n",
    "soup = BeautifulSoup(response.text)\n",
    "#get all the table rows\n",
    "table_rows = soup.find('tbody').findAll(\"tr\")\n",
    "\n",
    "# from each row get the state name and number of representatives and store in states_reps as a list of dictionaries\n",
    "states_reps = []\n",
    "for row in table_rows[:-1]:\n",
    "    [state_cell, numreps_cell]=row.findAll(\"td\")\n",
    "    state = state_cell.text.strip()\n",
    "    dists = int(numreps_cell.text.strip())\n",
    "    for dist in range(1, dists+1):\n",
    "        states_reps.append({\"State\": state, \"Dist\": str(dist)})\n",
    "\n",
    "#convert to a dataframe\n",
    "states_df = pd.DataFrame(states_reps)\n",
    "# merge this with the df containing state abbreviations to get the state abbreviations\n",
    "states_df= pd.merge(states_df, states_abbrev_df, on=\"State\")\n",
    "states_df[\"URL\"]=states_df.apply(lambda x: create_url(x[\"Abbreviation\"], x[\"Dist\"].zfill(2)), axis=1)\n",
    "states_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is just to test a random url (239) from states_df\n",
    "url = states_df[\"URL\"][239]\n",
    "get_all_candidates_for_district_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the candididate data from all URLS and store them in candidate_data, and then in a dataframe\n",
    "candidate_data = []\n",
    "for count, url in enumerate(states_df[\"URL\"]):\n",
    "    candidate_data.extend(get_all_candidates_for_district_url(url))\n",
    "    if count%20 == 0:\n",
    "        print(f\"{count} candidates processed out of {states_df.shape[0]}\")\n",
    "print(\"All done!!! Writing to dataframe...\")\n",
    "candidates_df = pd.DataFrame(candidate_data)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df.to_csv(\"../data/candidates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
